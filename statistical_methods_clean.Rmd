---
title: "statistical_methods_clean"
author: "E.M.Thomas"
date: "2024-02-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(janitor)
library(readxl)
library(countrycode)
library(broom)
library(here)
library(tidyr)
library(jtools)
library(caret)
library(AICcmodavg) 
library(equatiomatic)
library(zoo)
```

# Load and clean data
```{r}
# filter year for indexs
filter_year <- 2019 #to update across all dataframes 
```

### Functions
```{r}
# Define function to replace NAs with the most recent non-NA value within each group (country)
# For IUUFR dataset 
fill_na_last_non_na <- function(x) {
  if (any(!is.na(x))) {
    na.locf(x, na.rm = FALSE, fromLast = TRUE)
  } else {
    x
  }
}

# Define function to replace NA values with the mean of the respective indicator column
fill_na_mean <- function(x) {
  if (any(is.na(x))) {
    x[is.na(x)] <- mean(x, na.rm = TRUE)
  }
  x
}
```


### Skylight data
```{r}
### Organization engagements
organization_engagements <- read_csv(here("data", "Skylight Program Metrics_Organizations_Table.csv")) %>% clean_names()

### Weekly country engagements
weekly_country_engagements <- read_csv(here("data", "Skylight Program Metrics_Countries_Table.csv")) %>% clean_names()

weekly_country_engagements$country <- countrycode(weekly_country_engagements$country, "country.name", "country.name") 

weekly_country_engagements <- weekly_country_engagements%>% 
  filter(no_of_active_weeks >2) 

#list of active skylight countries 
active_skylight_countries <- weekly_country_engagements$country 

### Engagment sessions
skylight_engagement_sessions <- read_csv(here("data","Metrics_Countries_Pivot_table-2.csv")) %>% clean_names()

country_sessions <- skylight_engagement_sessions %>% 
  rename(country = engagement)

country_sessions$country <- countrycode(country_sessions$country, "country.name", "country.name") 

country_sessions <- country_sessions %>% 
  drop_na(country) %>% 
  group_by(country) %>%
  summarize(sessions = sum(sessions, na.rm = TRUE))

### Deals data
skylight_deal_dates <- read_excel(here("data", "updated deals.xlsx")) %>% clean_names()

skylight_deal_dates$deal_country[skylight_deal_dates$deal_country == "Micronesia"] <- "Federated States of Micronesia"

skylight_deal_dates$country <- countrycode(skylight_deal_dates$deal_country, "country.name", "country.name")
```

### IUUFR data
```{r}
# Read in and clean the IUUFR data
iuu_index_scores <- read_csv(here("data", "iuu_fishing_index_2019-2023_indicator_scores.csv")) %>% 
                clean_names() 
                
iuu_index_scores$country[iuu_index_scores$country == "Micronesia (FS of)"] <- "Federated States of Micronesia"
iuu_index_scores$country <- countrycode(iuu_index_scores$country, "country.name", "country.name") 
iuu_index_countries <- c(unique(iuu_index_scores$country))


# Make each indicator a separate column 
iuu_index_wide <- iuu_index_scores %>% 
  select(country, year, indicator_name, score) %>% 
  pivot_wider(names_from = "indicator_name", 
             values_from = "score") 

### Address NA values 
# Replacing NA values with either 1. the most recent non-NA value for the country-indicator group, if none exists, then replacing the NA values with the average of the entire column. Not sure if it's the best method but statistically should be ok. Real-world is more iffy since the NA values really don't apply. 


# Apply fill_na_last_non_na within each group (country)
iuu_index_wide <- iuu_index_wide %>%
  group_by(country) %>%
  mutate(across(2:42, fill_na_last_non_na)) %>%
  ungroup()

# Apply fill_na_mean only to NA values within each column
iuu_index_wide <- iuu_index_wide %>%
  mutate(across(2:42, fill_na_mean))


# Final IUUFR index to use to compile all indicator dataframes
iuufr_index_final <- iuu_index_wide %>% 
  group_by(country) %>% 
  summarise(across(2:42, mean, na.rm = TRUE))

```

### World Bank data

```{r}
### Governance indicators
# Read in and clean data
governance_indicators <- read_csv(here("data", "governance_indicators.csv")) %>% 
  clean_names() %>%
  rename_all(~ gsub("x(\\d+)_yr\\1", "\\1", .)) %>% 
  rename(country=country_name)

governance_indicators$country <- countrycode(governance_indicators$country,"country.name", "country.name")

# Extract the indicator estimates 
gov_id_estimates <- governance_indicators %>% 
  filter(grepl("EST", series_code)) %>% 
  mutate_all(~ ifelse(. == "..", NA, .)) %>%
  na.omit() #doesn't this get ride of all the NAs? COME BACK TO THIS

# Put all the indicators in separate columns 
wb_gov_index_df <- gov_id_estimates %>%
  pivot_longer(cols = 5:28,
               names_to = "year", 
               values_to = "value") %>% 
  subset(select = -series_code) %>% 
  pivot_wider(names_from = "series_name",
              values_from = "value") %>% 
  clean_names() %>% 
  filter(country %in% iuu_index_countries) %>% 
  select(-country_code) %>% 
  filter(year >= filter_year)

# Convert indicator scores to numeric
wb_gov_index_df$year <- as.numeric(wb_gov_index_df$year)
wb_gov_index_df$control_of_corruption_estimate <- as.numeric(wb_gov_index_df$control_of_corruption_estimate)
wb_gov_index_df$government_effectiveness_estimate <- as.numeric(wb_gov_index_df$government_effectiveness_estimate)
wb_gov_index_df$political_stability_and_absence_of_violence_terrorism_estimate <- as.numeric(wb_gov_index_df$political_stability_and_absence_of_violence_terrorism_estimate)
wb_gov_index_df$regulatory_quality_estimate <- as.numeric(wb_gov_index_df$regulatory_quality_estimate)
wb_gov_index_df$rule_of_law_estimate <- as.numeric(wb_gov_index_df$rule_of_law_estimate)
wb_gov_index_df$voice_and_accountability_estimate <- as.numeric(wb_gov_index_df$voice_and_accountability_estimate)

# Replace NA values with indicator mean, then get the mean for each indicator-country
gov_index_final <- wb_gov_index_df %>% 
  mutate(across(3:7, fill_na_mean)) %>% 
  group_by(country) %>% 
  summarise(across(3:7,mean, na.rm = TRUE))

```

```{r}
### Read in and clean WB GDP data
wb_gdp_df <- read_csv(here("data", "World Bank GDP 2.csv")) %>%
  rename(country=`Country Name`) %>% 
  select(-`Indicator Name`, -`Indicator Code`, -`Country Code`) 

wb_gdp_df$country <- countrycode(wb_gdp_df$country, "country.name", "country.name")

wb_gdp_final <- wb_gdp_df %>% 
  pivot_longer(cols = 2:64,
               names_to = "year", 
               values_to = "gdp") %>%
  group_by(country) %>%
  filter(!is.na(gdp)) %>%
  slice_max(order_by = year, n = 1) %>%
  ungroup() %>%
  distinct(country, .keep_all = TRUE) %>% 
  filter(country %in% iuu_index_countries) %>% 
  select(-year)

 
```


```{r}
### GDP per capita
wb_gdp_pc <- read_csv(here("data", "World Bank GDP per Capita.csv")) %>%
  rename(country=`Country Name`) %>% 
  select(-`Indicator Name`, -`Indicator Code`, -`Country Code`) 
wb_gdp_pc$country <- countrycode(wb_gdp_pc$country, "country.name", "country.name")

wb_gdp_pc_final <- wb_gdp_pc %>% 
  pivot_longer(cols = 2:64,
               names_to = "year", 
               values_to = "gdp_per_capita") %>% 
  group_by(country) %>%
  filter(!is.na(gdp_per_capita)) %>%
  slice_max(order_by = year, n = 1) %>%
  ungroup() %>%
  distinct(country, .keep_all = TRUE) %>% 
  filter(country %in% iuu_index_countries) %>% 
  select(-year)

```



```{r}
### Fish production indicators
##### OK so this was cleaned and exported, I think that should happen in another file 
fish_id_wide <- read_csv(here("data", "fish_indicators.csv")) %>%
  clean_names()

fish_id_clean <- fish_id_wide %>% 
  filter(year >= filter_year) %>% 
  select(-country_code, -country_name) %>% 
  filter(country %in% iuu_index_countries)

#### something is going on when I run this code (and others with fill_na_mean) that there is 1 less column then there actually is and I have to change it to one less column. Then it missed the column at the end. IDK whats going on, come back to this!!!
fish_index_final <- fish_id_clean %>% 
  mutate(across(2:4, fill_na_mean)) %>% 
  group_by(country) %>% 
  summarise(across(2:4,mean, na.rm = TRUE))

```


### Skylight treatment logic
```{r}
# Create a data frame with NAs #renamed from common_countries_df
skylight_treatment_df <- data.frame(country = iuu_index_countries, iuu_index_countries = NA, active_skylight_countries = NA)

# Fill in values in the data frame based on the presence in vectors
skylight_treatment_df$iuu_index_countries[match(iuu_index_countries, skylight_treatment_df$country)] <- iuu_index_countries
skylight_treatment_df$active_skylight_countries[match(active_skylight_countries, skylight_treatment_df$country)] <- active_skylight_countries

skylight_treatment_df$skylight_treatment <- ifelse(is.na(skylight_treatment_df$active_skylight_countries), 0, 1)

skylight_treatment_df <- skylight_treatment_df %>% select(country, skylight_treatment)


```


### Compile Skylight data
```{r}
ctk <- c("deal_title", "country", "deal_deployment_date", "deal_organisation","organization_type")

active_country_dates_df <- skylight_deal_dates %>% 
  subset(select = ctk) %>% 
  filter(deal_deployment_date > 2019) %>% 
  group_by(country) %>%
  filter(deal_deployment_date == min(deal_deployment_date, na.rm = TRUE)) %>%
  ungroup() %>%  #filter out duplicate country entries for country level analysis 
  distinct(country, deal_deployment_date, .keep_all = TRUE)

active_country_dates_clean <- active_country_dates_df %>% 
  mutate(treatment_year = as.integer(format(as.Date(deal_deployment_date), "%Y"))) %>% 
  filter(organization_type != "Regional") %>% #come back to this assumption later
  select(country, treatment_year) #%>% 
 # rename(deal_country = country)

# Combine all Skylight data into one df to use in final compilation
skylight_df_final <- skylight_treatment_df %>% 
  full_join(active_country_dates_clean, join_by(country)) %>% 
  full_join(weekly_country_engagements, join_by(country)) %>% 
  full_join(country_sessions, join_by(country))

skylight_df_final[is.na(skylight_df_final)] <- 0

skylight_df_final$skylight_treatment <- as.factor(skylight_df_final$skylight_treatment)

```


```{r}
### Compile IUUFR with governance indicators
countries_to_exclude <- 
  c("Montenegro", "Cook Islands", "Falkland Islands", "Pitcairn Islands", "RÃ©union", "Antarctica", "North Korea", "Taiwan")

all_index_df <- skylight_df_final %>% 
  full_join(gov_index_final, join_by(country)) %>% 
  full_join(iuufr_index_final, join_by(country)) %>% 
  full_join(fish_index_final, join_by(country)) %>% 
  full_join(wb_gdp_final, join_by(country)) %>% # still have NA values for Yemen and Venezuela, try applying na_fill function 
  full_join(wb_gdp_pc_final, join_by(country)) %>% 
  filter(!country %in% countries_to_exclude)

na_counts <- colSums(is.na(all_index_df))

all_indicators <- as.data.frame(unique(names(all_index_df[6:54])))

write.csv(all_indicators,"data/all_indicators.csv")
```


# Statistical Methods (these do not make any sense yet needs help)

### Scale the indicators
```{r}
# Standardize columns 6 to 49 in all_index_df
scaled_columns <- scale(all_index_df[, 6:54], center = TRUE, scale = TRUE)

# Combine scaled columns with non-scaled columns and preserve country and year columns
scaled_all_index_df <- cbind(all_index_df[, 1:5], as.data.frame(scaled_columns))

# Reorder so that response variable is next to the explanatory variables 
scaled_all_index_df <- scaled_all_index_df[, c(1, 3:5, 2, 6:54)] %>% 
  na.omit()

```

### Check for collinearity

```{r}
# Assuming your indicators are stored in a data frame called 'data'
cor_matrix <- cor(scaled_all_index_df[,6:54])

#Get the indices of highly correlated pairs
high_cor_indices <- which(abs(cor_matrix) > 0.7 & abs(cor_matrix) < 1, arr.ind = TRUE)

# Extract row and column names
high_cor_variables <- rownames(cor_matrix)[high_cor_indices[,1]]
high_cor_variables2 <- colnames(cor_matrix)[high_cor_indices[,2]]

# Combine variables into pairs
high_cor_pairs <- cbind(high_cor_variables, high_cor_variables2)

# Create a dataframe with pairs
high_cor_df <- data.frame(high_cor_pairs)

# exclude highly correlated indicators
remove_high_cor <- c("regulatory_quality_estimate", 
                     "rule_of_law_estimate", 
                     "voice_and_accountability_estimate", 
                     'Perception of levels of corruption',
                     "total_fisheries_production_metric_tons", 
                     'Volume of catches', 
                     'Gross national income per capita',
                     'Flag State is contracting party or cooperating non-contracting party to all relevant RFMOs',
                     'Number of fishing ports')

filtered_scaled_all_index_df <- scaled_all_index_df %>% 
  select(-remove_high_cor)
```

```{r}
# Try cor_matrix again with filtered down dataset

# Assuming your indicators are stored in a data frame called 'data'
cor_matrix_2 <- cor(filtered_scaled_all_index_df[,6:45])

#Get the indices of highly correlated pairs
high_cor_indices_2 <- which(abs(cor_matrix_2) > 0.7 & abs(cor_matrix_2) < 1, arr.ind = TRUE)

# Extract row and column names
high_cor_variables_2 <- rownames(cor_matrix_2)[high_cor_indices_2[,1]]
high_cor_variables2_2 <- colnames(cor_matrix_2)[high_cor_indices_2[,2]]

# Combine variables into pairs
high_cor_pairs_2 <- cbind(high_cor_variables_2, high_cor_variables2_2)

# Create a dataframe with pairs
high_cor_df_2 <- data.frame(high_cor_pairs_2)

remove_high_cor_2 <- c("political_stability_and_absence_of_violence_terrorism_estimate",
                       'Demand for MSC products')

filtered_scaled_all_index_df_2 <- filtered_scaled_all_index_df %>% 
  select(-remove_high_cor_2)
```



## Variance Inflation Factor
```{r}
# Subset the data to include only the relevant columns
subset_data <- filtered_scaled_all_index_df_2[, 5:43]

# Fit a linear model to calculate VIF
glm_model <- glm(skylight_treatment ~ ., data = subset_data, family=binomial)

# Calculate VIF for each predictor
vif_values <- car::vif(glm_model)

# Create a dataframe of predictor names and VIF values
vif_df <- data.frame(
  predictor = names(vif_values),
  vif_value = vif_values
)

# Arrange the dataframe in ascending order of VIF values
vif_df <- vif_df[order(vif_df$vif_value), ]

vif_id_keep <- vif_df[1:12, "predictor"]
```


```{r}
# Remove backticks from column names in vif_id_keep
cleaned_vif_id_keep <- gsub("`", "", vif_id_keep)

# Filter the original dataset to keep only the selected indicators and the first 6 columns
model_df_1 <- scaled_all_index_df %>%
  select(1:6, all_of(cleaned_vif_id_keep))
```


### Binomial Logistic Regression

##### Model 1 
```{r}
glm_1 <- glm(skylight_treatment ~ ., data = model_df_1[, 5:18], family = binomial)

# Extract coefficients, standard errors, z-values, and p-values from the summary
coef_summary <- summary(glm_1)$coefficients

# Convert the matrix to a dataframe
coef_df <- as.data.frame(coef_summary)

# Rename the columns for clarity
colnames(coef_df) <- c("Estimate", "Std.Error", "z value", "Pr(>|z|)")

# filter out p values greater than 0.2
filtered_coef_df <- coef_df %>% 
  filter(`Pr(>|z|)` <= 0.2)
```

##### Model 2
```{r}
# Extract the names of predictors with significant p-values from filtered_coef_df
filtered_coef_1 <- rownames(filtered_coef_df)

filtered_coef_1 <- gsub("`", "", filtered_coef_1)

# Filter model_df_1 to include only the columns corresponding to significant predictors
model_df_2 <- model_df_1[, c(1:6, which(colnames(model_df_1) %in% filtered_coef_1))]

glm_2 <- glm(skylight_treatment ~ ., data = model_df_2[, 5:12], family = binomial)

# Extract coefficients, standard errors, z-values, and p-values from the summary
coef_summary_2 <- summary(glm_2)$coefficients

# Convert the matrix to a dataframe
coef_df_2 <- as.data.frame(coef_summary_2)

# Rename the columns for clarity
colnames(coef_df_2) <- c("Estimate", "Std.Error", "z value", "Pr(>|z|)")

# filter out p values greater than 0.05
filtered_coef_df_2 <- coef_df_2 %>% 
  filter(`Pr(>|z|)` <= 0.05)

```


##### Model 3
```{r}
# list of significant indicators
filtered_coef_3 <- rownames(filtered_coef_df_2)
filtered_coef_3 <- gsub("`", "", filtered_coef_3)

# Filter model_df_1 to include only the columns corresponding to significant predictors
model_df_3 <- model_df_2[, c(1:6, which(colnames(model_df_2) %in% filtered_coef_3))]

glm_3 <- glm(skylight_treatment ~ ., data = model_df_3[, 5:9], family = binomial)

# Extract coefficients, standard errors, z-values, and p-values from the summary
coef_summary_3 <- summary(glm_3)$coefficients

# Convert the matrix to a dataframe
coef_df_3 <- as.data.frame(coef_summary_3)

# Rename the columns for clarity
colnames(coef_df_3) <- c("Estimate", "Std.Error", "z value", "Pr(>|z|)")



```



